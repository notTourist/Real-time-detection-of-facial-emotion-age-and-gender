# Real-time-detection-of-facial-emotion-age-and-gender

The project aimed to detect face emotion, age, and gender from a live video feed using pre-trained models. Haarcascades XML was used to detect faces from video frames. The pre-trained models were applied to the detected faces to obtain information about age, gender, and facial emotion. Different models were trained for each type of detection. The data was augmented and preprocessed using ImageDataGenerator. The face emotion detector model was trained for 10 epochs, resulting in a validation accuracy of 0.73. The gender detection CNN model was trained for 20 epochs, achieving a validation accuracy of 0.93. The age detection model was trained for 20 epochs and achieved a mean absolute error of 4.58 on the validation data. Then, the results were displayed by writing on the video frame using OpenCV
